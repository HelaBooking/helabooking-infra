# Setting Up Istio Service Mesh - For the Each Environment

This guide provides step-by-step instructions on how to set up the Istio Service Mesh for managing Zero Trust networking in different environments (development, staging, production).

## Important Points

- Istio Service Mesh will be deployed into each cluster's `istio-system` namespace
- Istio Base Helm chart is deployed in the `istio-system` namespace of each cluster under the `on-prem-management` or `cloud-management` branches. This is for shared use accross all environments.
- Istio Control Plane (Istiod) and Istio Ingress Gateway is manged by Helm Chart with terraform. While Virtual Services will be deployed in through the ArgoCD application. These will be done in each environment
- Since multiple Istio Control Planes are deployed, use `revision` based deployment for Istio Helm charts to avoid conflicts.
- There will be multiple Pod Monitorings and PeerAuthentications deployed in each environment for strict mTLS communication between services.

## Steps to Set Up Istio Service Mesh

1. **Deploy Istio Base Helm Chart**:
   - Switch to the `on-prem-management` or `cloud-management` branch first. Then create a new Helm release for Istio Base in the `management/deployments.tf` file. (Refer `/on-prem/management/deployments.tf` for existing Istio Base Helm release)
   - Commit the changes into relevant above branch to deploy automatically via Terraform.
2. **Deploy Istio Control Plane and Ingress Gateway using Helm**:
   - Switch to the respective environment branch (e.g., `env-dev`, `env-stag`, etc.). Then create a new Helm release for Istio Control Plane and Ingress Gateway in the `deployments.tf` file of the environment. (Refer the exsisting Helm chart configurations in the `on-prem/env-dev/deployments.tf` when creating new environment.)
   - Ensure to set the important parameters such as `revision`, `namespace`, `resource limits`, etc. for the Istio Control Plane in the Helm values.
   - Update the Lables set for the Istio Ingress Gateway Service such as `lable.istio` and `lable.app` to match with the Virtual Services that will be created via ArgoCD later.
   - Add the `istio.io/rev` label to the namespaces defined in the `networks.tf` file of the environment to enable automatic sidecar injection. (Refer `on-prem/env-dev/networks.tf` for existing configurations)
   - Commit the changes into relevant environment branch to deploy automatically via Terraform.
3. **Create Virtual Services using ArgoCD**:
   - Base Virtual Service, Ingress Gateway yaml files are available in the `helabooking-manifets` repository under the `base/networking` folder.
   - Update the `kustomization.yaml` file in the relevent environment folder (e.g., `env-dev`, `env-stag`, etc.) to include the base Virtual Service and Ingress Gateway yaml files.
   - Next, patch the Ingress Gateway Selector to match with the labels set in the Istio Ingress Gateway Service deployed via Helm. (Refer `helabooking-manifets/overlays/env-dev/kustomization.yaml` for existing configurations). Also patch the Virtual Services's host field to match with the DNS records created for the ingress.
   - Commit the changes into relevant environment branch to deploy automatically via ArgoCD.
4. **Deploy Kiali Dashboard (Optional)**:
   - If you wish to monitor the Istio Service Mesh using Kiali Dashboard, create a new Helm release for Kiali in the `deployments.tf` file of the environment. (Refer the exsisting Helm chart configurations in the `on-prem/env-dev/deployments.tf` when creating new environment.)
   - Ensure to set the important parameters such as `namespace`, `discovery.selector`, and `promtheus.url` for Kiali in the Helm values.
   - Commit the changes into relevant environment branch to deploy automatically via Terraform.
5. **Restart Pods to Inject Sidecars**:
   - Take a look at the current pods running and the container counts in the environment before restarting:
     `kubectl get pods -n <namespace>`
   - After deploying the Istio Control Plane and adding the `istio.io/rev` label to the namespaces, restart the all pods in the environment to ensure that the Istio sidecar proxies are injected properly.
   - You can do this by running the following command for each namespace in the environment:
     `kubectl rollout restart deployment -n <namespace>` or `kubectl delete pod --all -n <namespace>`
6. **Verify Istio Sidecar Injection**:
   - Check if the Istio sidecar proxies are injected into the pods by running:
     `kubectl get pods -n <namespace>`
   - You should see minumum two containers (the application container and the Istio sidecar proxy) for each pod. (Except prometheus node-exporter pods)
   - (Optional) Check the Kiali Dashboard's Applications and Services sections to verify that the pod ingestion and service configs are correctly deployed.
7. **Verify Application Traffic Routing**:
   - Test the application, Grafana, OpenSearch Dashboard, RabbitMQ endpoints to ensure that the traffic is being routed correctly through the Istio Ingress Gateway and Virtual Services.
   - You can use curl or a web browser to access the application URLs defined in the Virtual Services.
   - (Optional) After serveral requests, check the Kiali Dashboard's Graph section to visualize the traffic flow between services in the mesh. Enable the Security option in the graph to see mTLS communication status.
8. **Implement PodMonitoring and PeerAuthentication**:
   - To enforce mTLS communication between services, create PodMonitoring and PeerAuthentication resources in the relevent environment under `manifests.tf` file.
   - Refer the existing PodMonitoring and PeerAuthentication configurations in the `on-prem/env-dev/manifests.tf` file when creating new environment.
   - Remember to updates the `labels` for the Pod Monitoring using the Prometheus labels defined in the environment. Also update the `manifest_body` values to specify which namespaces to monitor.
   - Udpate the PeerAuthentication's `manifest_body` to set the mTLS mode as `STRICT`. And importantly, gather the services which communicates with outside the secured namespaces, such as Opensearch, Promtheus and set the `portLevelMtls` of thier ports to `PERMISSIVE` to enable non-mTLS communication as well. Otherwise will get `502/503` errors while accessing those services.
   - Commit the changes into relevant environment branch to deploy automatically via Terraform.
9. **Final Verification**:
   - After implementing the PodMonitoring and PeerAuthentication, verify that the mTLS communication is enforced between services.
   - You can check the Kiali Dashboard's Graph section to see the mTLS status of the communication between services.
   - Also, test and monitor the application and metrics to ensure that there are no connectivity issues.
   - If any issues arise, review the PeerAuthentication and PodMonitoring configurations to ensure they are set correctly.
