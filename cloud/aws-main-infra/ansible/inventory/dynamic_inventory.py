#!/usr/bin/env python3
import json
import os
import sys
import boto3

# --- CONFIGURATION (Variables at the top) ---
DEFAULT_REGION = os.environ.get('AWS_REGION', 'ap-southeast-1')
SSH_KEY_RELATIVE = "../keys/helabooking-cloud-k8s-node-key.pem"
SSH_KEY_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", SSH_KEY_RELATIVE))

# Path to the metadata.json generated by Terraform
METADATA_FILE = os.path.join(os.path.dirname(__file__), '../../metadata.json')
# --------------------------------------------

def get_metadata():
    if not os.path.exists(METADATA_FILE):
        # Fail loud if metadata is missing so know why it's not working
        sys.stderr.write(f"Error: Metadata file not found at {METADATA_FILE}\n")
        sys.exit(1)
    with open(METADATA_FILE, 'r') as f:
        return json.load(f)

def get_aws_instances(project_name, role_name, region):
    """Queries AWS for running instances with specific Project and Role tags."""
    # Added try/except for robust error handling
    try:
        ec2 = boto3.client('ec2', region_name=region)
        response = ec2.describe_instances(
            Filters=[
                {'Name': 'tag:Project', 'Values': [project_name]},
                {'Name': 'tag:Role', 'Values': [role_name]},
                {'Name': 'instance-state-name', 'Values': ['running']}
            ]
        )
        ips = []
        for reservation in response['Reservations']:
            for instance in reservation['Instances']:
                if 'PrivateIpAddress' in instance:
                    ips.append(instance['PrivateIpAddress'])
        return ips
    except Exception as e:
        sys.stderr.write(f"AWS Error: {e}\n")
        sys.exit(1)

def get_inventory():
    data = get_metadata()
    
    # Read Project Name from Metadata (Single Source of Truth)
    project_name = data.get("project_name")
    if not project_name:
        sys.stderr.write("Error: 'project_name' missing in metadata.json\n")
        sys.exit(1)
    
    # Logic Fixed: Use DEFAULT_REGION as fallback, assign to local variable current_region
    current_region = data.get("aws_region", DEFAULT_REGION)

    # Fetch Dynamic IPs
    master_ips = get_aws_instances(project_name, "master", current_region)
    worker_ips = get_aws_instances(project_name, "worker", current_region)

    return {
        "_meta": {
            "hostvars": {}
        },
        "all": {
            "vars": {
                "ansible_user": "ubuntu",
                # SSH Key Path relative to where you run ansible-playbook
                "ansible_ssh_private_key_file": SSH_KEY_PATH,
                
                # Proxy Command using Bastion Public IP from Metadata
                "ansible_ssh_common_args": f'-o ProxyCommand="ssh -o StrictHostKeyChecking=no -i \'{SSH_KEY_PATH}\' -W %h:%p ubuntu@{data["bastion_public_ip"]}"',
                
                # Global Variables for Playbooks
                "project_name": project_name,
                "aws_region": current_region,
                "s3_secrets_bucket": data.get("s3_secrets_bucket"),
                "bootstrap_secret_id": data.get("bootstrap_secret_id"),
                "k8s_api_endpoint": data.get("k8s_api_endpoint")
            }
        },
        "masters": { "hosts": master_ips },
        "workers": { "hosts": worker_ips },
        "vpn": {
            "hosts": [data["vpn_public_ip"]],
            "vars": {
                # Inherit the ProxyCommand from the 'all' group.
        "vpn_private_ip": data.get("vpn_private_ip")
    }
}
    }

if __name__ == "__main__":
    print(json.dumps(get_inventory()))